{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e22eb5e-571e-4995-9417-7533b2c4b277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sqlite3, pandas as pd\n",
    "\n",
    "def load_sql(db_name, tbl_name):\n",
    "    \"\"\"Load SQLite database.\"\"\"\n",
    "    con = sqlite3.connect(f\"database/{db_name}.db\")\n",
    "    df = pd.read_sql(f\"SELECT * FROM {tbl_name}\", con)\n",
    "    con.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d03d87f-1fe7-4637-90ca-021ee2d29848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_x</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>user_location</th>\n",
       "      <th>place_name</th>\n",
       "      <th>place_id</th>\n",
       "      <th>place_full_name</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>postcode</th>\n",
       "      <th>country</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>region</th>\n",
       "      <th>district</th>\n",
       "      <th>county</th>\n",
       "      <th>rulebased_sent</th>\n",
       "      <th>nb_sent</th>\n",
       "      <th>svm_sent</th>\n",
       "      <th>dl_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>1587495934644076548</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>reminder bp stand british petroleum owned gove...</td>\n",
       "      <td>None</td>\n",
       "      <td>Garston</td>\n",
       "      <td>12f69ad404352073</td>\n",
       "      <td>Garston, England</td>\n",
       "      <td></td>\n",
       "      <td>L19 5NB</td>\n",
       "      <td>England</td>\n",
       "      <td>-2.886266</td>\n",
       "      <td>53.358869</td>\n",
       "      <td>North West</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>1590093953483018240</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>sane thinking mind uk approach different count...</td>\n",
       "      <td>None</td>\n",
       "      <td>Dewsbury</td>\n",
       "      <td>43dacd36a372f0d8</td>\n",
       "      <td>Dewsbury, England</td>\n",
       "      <td>refugees</td>\n",
       "      <td>WF17 7JZ</td>\n",
       "      <td>England</td>\n",
       "      <td>-1.636520</td>\n",
       "      <td>53.701937</td>\n",
       "      <td>Yorkshire and The Humber</td>\n",
       "      <td>Kirklees</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1588984083375620096</td>\n",
       "      <td>2022-11-05</td>\n",
       "      <td>earlier afternoon arrived edinburgh driving ai...</td>\n",
       "      <td>14 Royal Terrace, Edinburgh</td>\n",
       "      <td>Queensferry</td>\n",
       "      <td>49f93f5ee9d57aff</td>\n",
       "      <td>Queensferry, Scotland</td>\n",
       "      <td></td>\n",
       "      <td>EH30 9NF</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>-3.399317</td>\n",
       "      <td>55.987232</td>\n",
       "      <td>None</td>\n",
       "      <td>City of Edinburgh</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>1580098894339657729</td>\n",
       "      <td>2022-10-12</td>\n",
       "      <td>far biggest contributor military financial hum...</td>\n",
       "      <td>Cardiff, Wales</td>\n",
       "      <td>Cardiff</td>\n",
       "      <td>68f3012fe4848e35</td>\n",
       "      <td>Cardiff, Wales</td>\n",
       "      <td></td>\n",
       "      <td>CF14 3UU</td>\n",
       "      <td>Wales</td>\n",
       "      <td>-3.194773</td>\n",
       "      <td>51.496873</td>\n",
       "      <td>None</td>\n",
       "      <td>Cardiff</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>1585694728841986070</td>\n",
       "      <td>2022-10-27</td>\n",
       "      <td>russia good ukraine bad corrupt country bring ...</td>\n",
       "      <td>Stoke Poges, South East</td>\n",
       "      <td>South East</td>\n",
       "      <td>06168d1feda43857</td>\n",
       "      <td>South East, England</td>\n",
       "      <td></td>\n",
       "      <td>RG30 2DQ</td>\n",
       "      <td>England</td>\n",
       "      <td>-0.993347</td>\n",
       "      <td>51.451211</td>\n",
       "      <td>South East</td>\n",
       "      <td>Reading</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id_x  created_at  \\\n",
       "1666  1587495934644076548  2022-11-01   \n",
       "2803  1590093953483018240  2022-11-08   \n",
       "417   1588984083375620096  2022-11-05   \n",
       "1173  1580098894339657729  2022-10-12   \n",
       "229   1585694728841986070  2022-10-27   \n",
       "\n",
       "                                                   text  \\\n",
       "1666  reminder bp stand british petroleum owned gove...   \n",
       "2803  sane thinking mind uk approach different count...   \n",
       "417   earlier afternoon arrived edinburgh driving ai...   \n",
       "1173  far biggest contributor military financial hum...   \n",
       "229   russia good ukraine bad corrupt country bring ...   \n",
       "\n",
       "                    user_location   place_name          place_id  \\\n",
       "1666                         None      Garston  12f69ad404352073   \n",
       "2803                         None     Dewsbury  43dacd36a372f0d8   \n",
       "417   14 Royal Terrace, Edinburgh  Queensferry  49f93f5ee9d57aff   \n",
       "1173               Cardiff, Wales      Cardiff  68f3012fe4848e35   \n",
       "229       Stoke Poges, South East   South East  06168d1feda43857   \n",
       "\n",
       "            place_full_name  hashtags  postcode   country  longitude  \\\n",
       "1666       Garston, England             L19 5NB   England  -2.886266   \n",
       "2803      Dewsbury, England  refugees  WF17 7JZ   England  -1.636520   \n",
       "417   Queensferry, Scotland            EH30 9NF  Scotland  -3.399317   \n",
       "1173         Cardiff, Wales            CF14 3UU     Wales  -3.194773   \n",
       "229     South East, England            RG30 2DQ   England  -0.993347   \n",
       "\n",
       "       latitude                    region           district county  \\\n",
       "1666  53.358869                North West          Liverpool   None   \n",
       "2803  53.701937  Yorkshire and The Humber           Kirklees   None   \n",
       "417   55.987232                      None  City of Edinburgh   None   \n",
       "1173  51.496873                      None            Cardiff   None   \n",
       "229   51.451211                South East            Reading   None   \n",
       "\n",
       "      rulebased_sent  nb_sent  svm_sent  dl_sent  \n",
       "1666               0        0         0        0  \n",
       "2803               0        0         0        0  \n",
       "417                0        1         0        0  \n",
       "1173               0        0         0        0  \n",
       "229                0        0         0        0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_sql(\"tweets_v7\", \"tweets_v7\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663ccb4d-ae7d-4585-a42c-2bdc39b3b0d7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------- #\n",
    "#                     t-SNE clustering                        #\n",
    "# ----------------------------------------------------------- #\n",
    "# This code has been adapted from:\n",
    "# Prabhakaran, S. (2018). Topic modeling visualisation - How to present the results of LDA models? [online] Machinelearningplus.com. Available at: https://www.machinelearningplus.com/nlp/topic-modeling-visualization-how-to-present-results-lda-models/ [Accessed 2 Dec. 2022].\n",
    "\n",
    "# from sklearn.manifold import TSNE\n",
    "# from bokeh.plotting import figure, output_file, show\n",
    "# from bokeh.models import Label\n",
    "# from bokeh.io import output_notebook\n",
    "# import matplotlib.colors as mcolors\n",
    "\n",
    "# # Get topic weights\n",
    "# # topic_weights = []\n",
    "# # for row_list in lda_para_model.components_:\n",
    "# #     topic_weights.append([w for w in row_list])\n",
    "\n",
    "# topic_weights = []\n",
    "# for row_list in lda_para_model.components_:\n",
    "#     topic_weights.append([w for w in row_list])\n",
    "    \n",
    "# # Array of topic weights\n",
    "# arr = pd.DataFrame(topic_weights).fillna(0).values\n",
    "\n",
    "# # Keep the well separated points (optional)\n",
    "# arr = arr[np.amax(arr, axis=1) > 0.35]\n",
    "\n",
    "# # Dominant topic number in each tweet\n",
    "# topic_num = np.argmax(arr, axis=1)\n",
    "\n",
    "# # tSNE dimension reduction\n",
    "# tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
    "# tsne_lda = tsne_model.fit_transform(arr)\n",
    "\n",
    "# # plot the topic clusters using Bokeh\n",
    "# output_notebook()\n",
    "# n_topics = 4\n",
    "# mycolors = np.array([color for name, color in mcolors.TABLEAU_COLORS.items()])\n",
    "# plot = figure(title=\"t-SNE Clustering of {} LDA Topics\".format(n_topics), \n",
    "#               plot_width=900, plot_height=700)\n",
    "# plot.scatter(x=tsne_lda[:,0], y=tsne_lda[:,1], color=mycolors[topic_num])\n",
    "# show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a38ef42-c606-4fb0-8e77-c227c3334aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------- #\n",
    "#    Calculating Topic Distribution of Documents Over Time    #\n",
    "# ----------------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b1a47a-8a02-452e-8ba0-7f38885104f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "days_data = []\n",
    "days = np.unique(df['created_at'])\n",
    "\n",
    "for day in days:\n",
    "  W_day = lda_para_model.transform(count_para_vectors[days == day])\n",
    "  days_data.append([day] + list(W_day.sum(axis=0) / W_day.sum() * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e79e22-549a-46ef-b7fb-caa0c294f079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topic_names = []\n",
    "voc = count_para_vectorizer.get_feature_names_out()\n",
    "\n",
    "for topic in lda_para_model.components_:\n",
    "  important = topic.argsort()\n",
    "  top_word = voc[important[-1]] + \" \" + voc[important[-2]]\n",
    "  topic_names.append(\"Topic \" + top_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a817ce50-24cc-4258-85d5-17d3d26ace59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "df_days = pd.DataFrame(days_data, columns=['day'] + topic_names).set_index('day')\n",
    "df_days.plot.area(figsize=(16,6))\n",
    "\n",
    "plt.title('Topics Distribition over Time')\n",
    "plt.savefig(\"figures/topics_distribution.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a96eed-2a37-465f-81c8-c9bdd25a658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------- #\n",
    "#                    Training SVC model                       #\n",
    "# ----------------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f255a150-5a5f-42f5-8b0f-eeb9ef013a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'], \n",
    "    df['rulebased_sent'],\n",
    "    test_size=0.2,\n",
    "    train_size=0.8,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=df['rulebased_sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44be46f-6f75-479e-b5e9-8cdf8f524a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X_train_tf = tfidf.fit_transform(X_train)\n",
    "X_test_tf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0780565f-07a5-4527-8ea0-7960242a5777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "model = svm.SVC(kernel='linear')\n",
    "model.fit(X_train_tf, y_train)\n",
    "\n",
    "Y_pred = model.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73d0c6d-625c-4932-a8c8-93ffe200c399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# print(\"Accuracy score: \", accuracy_score(y_test, Y_pred))\n",
    "# print(classification_report(y_test, Y_pred))\n",
    "# print(confusion_matrix(y_test, Y_pred))\n",
    "\n",
    "def create_confusion_matrix(y_test, Y_pred, title=\"Confusion Matrix\"):\n",
    "    cm = confusion_matrix(y_test, Y_pred)\n",
    "    cm = cm / np.sum(cm)\n",
    "\n",
    "    ax = sns.heatmap(cm, annot=True, cmap=\"Greens\", fmt=\".2%\")\n",
    "\n",
    "    ax.set_title(f\"{title}\\n\")\n",
    "    ax.set_xlabel(\"Predicted Values\")\n",
    "    ax.set_ylabel(\"Actual Values\")\n",
    "\n",
    "    ax.xaxis.set_ticklabels([\"Negative\", \"Positive\"])\n",
    "    ax.yaxis.set_ticklabels([\"Negative\", \"Positive\"])\n",
    "\n",
    "    title = title.replace(\" \", \"_\")\n",
    "    plt.savefig(f\"figures/{title}.jpg\")\n",
    "    \n",
    "create_confusion_matrix(y_test, Y_pred, title=\"SVC Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c619bdb-c7da-4737-bdcf-a34d9f2e8a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------- #\n",
    "#            Tuning BERTweet deep learning model              #\n",
    "# ----------------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ca1531-ac22-499b-a130-2c4117128e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataset into dependent and independent features\n",
    "X = list(df['text'])\n",
    "y = list(df['rulebased_sent'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c8e365-4702-4bbe-b1d9-e40085a38c77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"vinai/bertweet-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "train_encodings = tokenizer(X_train, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(X_test, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eb5939-eefe-4e19-b9c9-50b6665d476b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7528e092-4efe-4cb0-b539-d39dbc9d13e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "  metrics = ['accuracy', 'recall', 'precision', 'f1']\n",
    "  metric = {}\n",
    "  for met in metrics:\n",
    "    metric[met] = load_metric(met)\n",
    "  logits, labels = eval_pred\n",
    "  predictions = np.argmax(logits, axis=-1)\n",
    "  metric_res = {}\n",
    "  for met in metrics:\n",
    "    metric_res[met] = metric[met].compute(predictions=predictions, references=labels)[met]\n",
    "  return metric_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0ce1c1-525b-400e-a492-58f6b6acc30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFTrainingArguments\n",
    "\n",
    "training_args = TFTrainingArguments(output_dir='./results',\n",
    "                                    num_train_epochs=3,\n",
    "                                    per_device_train_batch_size=4,\n",
    "                                    per_device_eval_batch_size=8,\n",
    "                                    warmup_steps=20,\n",
    "                                    weight_decay=0.01,\n",
    "                                    logging_dir='./logs',\n",
    "                                    logging_steps=3,\n",
    "                                    logging_strategy='epoch',\n",
    "                                    evaluation_strategy='epoch',\n",
    "                                    eval_steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9658fa3-6ebe-492a-816c-cf85e92c82fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification, TFTrainer\n",
    "\n",
    "with training_args.strategy.scope():\n",
    "    model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    \n",
    "trainer = TFTrainer(model=model,\n",
    "                    args=training_args,\n",
    "                    train_dataset=train_dataset,\n",
    "                    eval_dataset=test_dataset,\n",
    "                    compute_metrics=compute_metrics)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d79d6d-334e-45f0-ab07-c3353ad0b0aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate BERTweet model\n",
    "trainer.evaluate(test_dataset)\n",
    "\n",
    "output = trainer.predict(test_dataset)\n",
    "predictions = output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f36b7be-be90-4c4d-a26e-9470a58752ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, output[1]))\n",
    "create_confusion_matrix(y_test, predictions, \"BERTweet Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38c99ed-56c2-47b7-899d-9f79d5607649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
